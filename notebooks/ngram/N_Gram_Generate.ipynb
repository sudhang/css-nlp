{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhang/css-nlp/blob/master/ngram/N_Gram_Generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make it pretty\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "zXfXqv_XmHtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will use the N-Gram model from nltk, using the MLE.  We have previously saved this model to disk and can load it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_hDYvccowjpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations"
      ],
      "metadata": {
        "id": "GKE7r6Z9w5Hi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hkn_4CgUuUTK",
        "outputId": "f851df33-eb3a-4bff-e316-778451564400"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FLAGS and PARAMS"
      ],
      "metadata": {
        "id": "zsN3gcSo9N-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVEPATH = \"/content/drive/MyDrive/TU/Sem 4/NLP\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4wb3JlM5hhtE",
        "outputId": "b1a4643e-f58a-4e47-a57b-0757ec0268a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "NUM_TO_GEN = 20\n",
        "N = 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_tjlGXF69PwV",
        "outputId": "cf3eb556-1742-4478-a076-c89adbcabc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "To use the llama2 models from huggingface, we need to input an access token."
      ],
      "metadata": {
        "id": "GZUCvVv2xbWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "wM3YbedRxosD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fcdae26f-c005-4760-ad36-dd80ae069841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "-JlR07LxZtkY",
        "outputId": "9505de10-8ed2-4b2f-841c-5d253517e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a previous model"
      ],
      "metadata": {
        "id": "qwmqKRqsaMSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h5btQQkAJHvA",
        "outputId": "43e91162-a8bb-4279-c340-1e7d8cb859a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{GDRIVEPATH}/models/ngram_nyt_{N}.pkl\", 'rb') as f:\n",
        "    the_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "n5T6hQuqaN3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0d11f2b8-6fb3-45c1-de93-faac50f2156f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(the_model.counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "33Femaz0K7E7",
        "outputId": "c46b5db2-1e4b-4db8-be1c-0b0b156cc0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 6 ngram orders and 84643935 ngrams>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "the_model.counts[\"Barack\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DjyIraz-LNRo",
        "outputId": "84ae7ab3-9849-40b4-cdd8-e2e092416783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1237"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "the_model.score(\"Obama\", [\"Barack\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Ja3jpRPcLeNi",
        "outputId": "afd785e1-d44b-4f9f-8b21-666cbea0c9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9902991107518189"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation\n"
      ],
      "metadata": {
        "id": "hOc3mvvkAd3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, prompt=[\"Graz\"], random_seed=None):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed, text_seed=prompt):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)\n",
        "if DEBUG:\n",
        "  prompt = \"MEXICO CITY — Mexico’s most prominent human rights lawyers, journalists and anti-corruption activists have been targeted by advanced spyware sold to the Mexican government on the condition that it be used only to investigate criminals and terrorists. The targets include lawyers looking into the mass disappearance of 43 students, a highly respected academic who helped write anti-corruption legislation, two of Mexico’s most influential journalists and an American representing victims of sexual abuse by the police.\"\n",
        "  prompt_tokens = nltk.word_tokenize(prompt)\n",
        "  the_gen_text = prompt + generate_sent(the_model, num_words=200, prompt=prompt_tokens)\n",
        "  the_gen_text"
      ],
      "metadata": {
        "id": "MtON793rArzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_sentences(text_list):\n",
        "    total_sentences = 0\n",
        "    for text in text_list:\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        total_sentences += len(sentences)\n",
        "    return total_sentences\n",
        "\n",
        "# Example usage:\n",
        "text_list = [\n",
        "    \"This is the first sentence. This is the second sentence.\",\n",
        "    \"This is another sentence.\"\n",
        "  ]\n",
        "print(count_sentences(text_list))  # Output: 3\n"
      ],
      "metadata": {
        "id": "l-lbmF25HBxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_news_article(prompt=\"Graz, Austria - \", min_sentences = 50):\n",
        "\n",
        "  gen_text_snippets = [prompt]\n",
        "  prompt_tokens = nltk.word_tokenize(prompt)\n",
        "  count_gen_sentences = count_sentences(gen_text_snippets)\n",
        "\n",
        "  while count_gen_sentences < min_sentences:\n",
        "\n",
        "\n",
        "    last_gen_snippet = gen_text_snippets[-1].rstrip('. ')\n",
        "                                                # rstrip('. ') to trick it into\n",
        "                                                # thinking the sentence isn't\n",
        "                                                # over so that it doesn't decide\n",
        "                                                # to go on a tangent\n",
        "\n",
        "    inputs = nltk.word_tokenize(last_gen_snippet)\n",
        "\n",
        "    gen_text = generate_sent(the_model, num_words=200, prompt=prompt_tokens)\n",
        "    gen_text_snippets.append(gen_text)\n",
        "\n",
        "    count_gen_sentences = count_sentences(gen_text_snippets)\n",
        "\n",
        "    if DEBUG:\n",
        "      print(f\"{gen_text=}\\n{count_gen_sentences=}====\\n\")\n",
        "\n",
        "  gen_text = \" \".join(gen_text_snippets)\n",
        "\n",
        "  return gen_text\n",
        "\n"
      ],
      "metadata": {
        "id": "M1k87t9WFr9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DEBUG:\n",
        "  the_prompt = \"NEW DELHI - Thousands of people were evacuated from their homes \"\n",
        "  article = generate_news_article(prompt = the_prompt, min_sentences=51)\n",
        "  display(article)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "U39dHhX7IWP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the csv file\n",
        "df = pd.read_csv(f'{GDRIVEPATH}/data/nyt_test.csv')\n",
        "\n",
        "# Initialize a new dataframe\n",
        "new_df = pd.DataFrame(columns=['Original Article', 'Prompt', 'Generated Article'])\n",
        "\n",
        "for i in range(NUM_TO_GEN):\n",
        "    random_article = df['content'].sample(1).values[0]\n",
        "\n",
        "    sentences = nltk.sent_tokenize(random_article)\n",
        "    # Use the first two sentences of the real article as the prompt\n",
        "    prompt = ' '.join(sentences[:2])\n",
        "\n",
        "    generated_article = generate_news_article(prompt=prompt, min_sentences=51)\n",
        "\n",
        "    current_df = pd.DataFrame({\n",
        "        'Original Article': [random_article],\n",
        "        'Prompt': [prompt],\n",
        "        'Generated Article': [generated_article]\n",
        "    })\n",
        "\n",
        "    # Append the current dataframe to the new dataframe\n",
        "    new_df = pd.concat([new_df, current_df], ignore_index=True)\n",
        "\n",
        "# Post-processing to remove incomplete sentences\n",
        "new_df['Generated Article'] = new_df['Generated Article'].apply(lambda text:\n",
        "                                      ' '.join(nltk.sent_tokenize(text)[:-1])\n",
        "                                      if not text.endswith(('.', '!', '?'))\n",
        "                                      else text\n",
        "                                    )\n"
      ],
      "metadata": {
        "id": "Dgv4qXZTy0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_string = new_df.loc[4,\"Generated Article\"]\n",
        "orig_string"
      ],
      "metadata": {
        "id": "eLOT7VeVm15l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Processing"
      ],
      "metadata": {
        "id": "pbOY0_tEWnc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def post_process(text):\n",
        "    # Remove double punctuation\n",
        "    text = re.sub(r'[!?]{2,}', r'', text)\n",
        "\n",
        "    # Remove spaces before punctuation\n",
        "    text = re.sub(r'\\s*([.,!?])', r'\\1', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = text.strip()\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "\n",
        "    #Removes whitespaces around contraction marks in a string.\n",
        "    pattern = r'\\s([\\'’])\\s'\n",
        "    text = re.sub(pattern, r'\\1', text)\n",
        "\n",
        "    #Removes whitespaces around opening quote marks in a string.\n",
        "    pattern = r'“\\s'\n",
        "    text = re.sub(pattern, r'“', text)\n",
        "\n",
        "    #Removes whitespaces around closing quote marks in a string.\n",
        "    pattern = r'\\s”'\n",
        "    text = re.sub(pattern, r'”', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "new_df['Generated Article'] = new_df['Generated Article'].apply(post_process)"
      ],
      "metadata": {
        "id": "l-FWHHAMWr_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the new dataframe to a csv file\n",
        "new_df.to_csv(f'{GDRIVEPATH}/generated/ngram_nyt_{N}.csv', index=False)"
      ],
      "metadata": {
        "id": "i3e5y7mx2gwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "UCm5iFPtNpdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.loc[4,\"Generated Article\"]"
      ],
      "metadata": {
        "id": "UH1-fC2RNplg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}